{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dfa140",
   "metadata": {},
   "source": [
    "# Auto Insurance Claim Frequency Modeling\n",
    "\n",
    "**Author:** Ben Honil \n", 
    "**Institution:** ESILV - École Supérieure d'Ingénieurs Léonard de Vinci  \n",
    "**Program:** Master 1 - Actuarial Science  \n",
    "**Date:** December 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd66d61",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376f920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and Models\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_poisson_deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33295793",
   "metadata": {},
   "source": [
    "### 1.1 Loading the Dataset\n",
    "\n",
    "We use the `freMTPL2freq` dataset (French Motor Third-Party Liability claim frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecd4951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 678013 entries, 0 to 678012\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   IDpol       678013 non-null  float64\n",
      " 1   ClaimNb     678013 non-null  int64  \n",
      " 2   Exposure    678013 non-null  float64\n",
      " 3   Area        678013 non-null  object \n",
      " 4   VehPower    678013 non-null  int64  \n",
      " 5   VehAge      678013 non-null  int64  \n",
      " 6   DrivAge     678013 non-null  int64  \n",
      " 7   BonusMalus  678013 non-null  int64  \n",
      " 8   VehBrand    678013 non-null  object \n",
      " 9   VehGas      678013 non-null  object \n",
      " 10  Density     678013 non-null  int64  \n",
      " 11  Region      678013 non-null  object \n",
      "dtypes: float64(2), int64(6), object(4)\n",
      "memory usage: 62.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"freMTPL2freq.csv\")\n",
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3caad4",
   "metadata": {},
   "source": [
    "### 1.2 General Description\n",
    "\n",
    "Each row corresponds to an auto insurance contract.\n",
    "\n",
    "**Main variables:**\n",
    "- `IDpol`: Policy identifier (technical, not predictive)\n",
    "- `ClaimNb`: Number of claims observed during the period (target variable)\n",
    "- `Exposure`: Exposure duration (in years, between 0 and 1)\n",
    "- `Area`, `Region`: Geographic information\n",
    "- `VehPower`, `VehAge`, `VehBrand`, `VehGas`: Vehicle characteristics\n",
    "- `DrivAge`: Driver's age\n",
    "- `BonusMalus`: Bonus-malus coefficient\n",
    "- `Density`: Population density of the residence area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e78bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th></th><th>IDpol</th><th>ClaimNb</th><th>Exposure</th><th>Area</th><th>VehPower</th><th>VehAge</th><th>DrivAge</th><th>BonusMalus</th><th>VehBrand</th><th>VehGas</th><th>Density</th><th>Region</th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th>0</th><td>1.0</td><td>1</td><td>0.10</td><td>D</td><td>5</td><td>0</td><td>55</td><td>50</td><td>B12</td><td>Regular</td><td>1217</td><td>R82</td></tr>\n",
       "    <tr><th>1</th><td>3.0</td><td>1</td><td>0.77</td><td>D</td><td>5</td><td>0</td><td>55</td><td>50</td><td>B12</td><td>Regular</td><td>1217</td><td>R82</td></tr>\n",
       "    <tr><th>2</th><td>5.0</td><td>1</td><td>0.75</td><td>B</td><td>6</td><td>2</td><td>52</td><td>50</td><td>B12</td><td>Diesel</td><td>54</td><td>R22</td></tr>\n",
       "    <tr><th>3</th><td>10.0</td><td>1</td><td>0.09</td><td>B</td><td>7</td><td>0</td><td>46</td><td>50</td><td>B12</td><td>Diesel</td><td>76</td><td>R72</td></tr>\n",
       "    <tr><th>4</th><td>11.0</td><td>1</td><td>0.84</td><td>B</td><td>7</td><td>0</td><td>46</td><td>50</td><td>B12</td><td>Diesel</td><td>76</td><td>R72</td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDpol  ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand   VehGas  Density Region\n",
       "0    1.0        1      0.10    D         5       0       55          50      B12  Regular     1217    R82\n",
       "1    3.0        1      0.77    D         5       0       55          50      B12  Regular     1217    R82\n",
       "2    5.0        1      0.75    B         6       2       52          50      B12   Diesel       54    R22\n",
       "3   10.0        1      0.09    B         7       0       46          50      B12   Diesel       76    R72\n",
       "4   11.0        1      0.84    B         7       0       46          50      B12   Diesel       76    R72"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93efe04",
   "metadata": {},
   "source": [
    "## 2. Descriptive Analysis and Visualization\n",
    "\n",
    "We first examine the distribution of the target variable `ClaimNb` and the exposure `Exposure`. We also create the frequency variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1def9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th></th><th>IDpol</th><th>ClaimNb</th><th>Exposure</th><th>VehPower</th><th>VehAge</th><th>DrivAge</th><th>BonusMalus</th><th>Density</th><th>Frequency</th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th>count</th><td>678013</td><td>678013</td><td>678013</td><td>678013</td><td>678013</td><td>678013</td><td>678013</td><td>678013</td><td>678013</td></tr>\n",
       "    <tr><th>mean</th><td>3.44e+06</td><td>0.053</td><td>0.528</td><td>6.48</td><td>7.04</td><td>45.5</td><td>59.8</td><td>1792</td><td>0.197</td></tr>\n",
       "    <tr><th>std</th><td>1.96e+06</td><td>0.238</td><td>0.318</td><td>2.14</td><td>5.67</td><td>14.2</td><td>15.6</td><td>3958</td><td>1.84</td></tr>\n",
       "    <tr><th>min</th><td>1.0</td><td>0</td><td>0.002</td><td>4</td><td>0</td><td>18</td><td>50</td><td>1</td><td>0</td></tr>\n",
       "    <tr><th>max</th><td>6.11e+06</td><td>4</td><td>1.0</td><td>15</td><td>100</td><td>100</td><td>230</td><td>27000</td><td>500</td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Descriptive statistics for numerical variables"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create frequency: ClaimNb / Exposure\n",
    "df['Frequency'] = df['ClaimNb'] / df['Exposure']\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "claim_dist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClaimNb Distribution:\n",
      "0 claims: 643,212 (94.87%)\n",
      "1 claims: 32,986 (4.87%)\n",
      "2 claims: 1,715 (0.25%)\n",
      "3 claims: 93 (0.01%)\n",
      "4 claims: 7 (0.00%)\n",
      "\n",
      "Zero-inflation rate: 94.87%\n"
     ]
    }
   ],
   "source": [
    "# Distribution of ClaimNb\n",
    "print(\"ClaimNb Distribution:\")\n",
    "for i in range(5):\n",
    "    count = (df['ClaimNb'] == i).sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"{i} claims: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nZero-inflation rate: {(df['ClaimNb'] == 0).sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "correlation_matrix.png",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation between numerical variables\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.corr(numeric_only=True), cmap=\"coolwarm\", annot=True)\n",
    "plt.title(\"Correlation Matrix (Numerical Variables)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762af7b",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The correlation matrix reveals only weak correlations between numerical variables and the target variable.\n",
    "This is expected in a context of highly imbalanced claim data (ClaimNb ≈ 0 for the majority of contracts).\n",
    "Linear correlation is not suitable for evaluating variable relevance in a Poisson or non-linear model.\n",
    "Variables may have real predictive importance despite near-zero correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a3afb",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "\n",
    "- The mean of `ClaimNb` is very low (~0.05), meaning a large majority of contracts have no claims (highly imbalanced data)\n",
    "- The average frequency (`ClaimNb / Exposure`) is also low, with many zeros and some very high values when a claim occurs on short exposure\n",
    "- This behavior is typical of **rare count data**, well-suited for Poisson regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bfa1f",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing\n",
    "\n",
    "We apply simple cleaning rules to remove outliers:\n",
    "- Remove drivers under 18 years old\n",
    "- Keep vehicles with reasonable age (≤ 30 years)\n",
    "- Remove rows with zero Exposure (to avoid division by zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c855cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676897, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple outlier filtering\n",
    "df = df[df['DrivAge'] >= 18]\n",
    "df = df[df['VehAge'] <= 30]\n",
    "df = df[df['Exposure'] > 0]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c87cd6",
   "metadata": {},
   "source": [
    "### 3.1 Categorical Variable Encoding\n",
    "\n",
    "Scikit-learn models don't handle categorical variables directly, so we use **one-hot encoding** via `pd.get_dummies`, dropping one reference category (`drop_first=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5316d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676897, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['Area', 'VehBrand', 'VehGas', 'Region']\n",
    "\n",
    "df1 = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef113be",
   "metadata": {},
   "source": [
    "The `drop_first=True` option removes the first category of each categorical variable, avoiding **perfect collinearity** (the missing category can be inferred from the others)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099593c",
   "metadata": {},
   "source": [
    "## 4. Target Definition and Train/Test Split\n",
    "\n",
    "We aim to predict the **number of claims `ClaimNb`** from other variables.\n",
    "\n",
    "We remove from X:\n",
    "- `ClaimNb` (target)\n",
    "- `Frequency` (derived from ClaimNb and Exposure)\n",
    "- `IDpol` (technical identifier, not informative)\n",
    "\n",
    "We keep `Exposure` in df1 to potentially use it as **weights** in Poisson regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37920e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((541517, 43), (135380, 43))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target variable\n",
    "y = df1['ClaimNb']\n",
    "\n",
    "# Features: remove ClaimNb, Frequency and IDpol\n",
    "X = df1.drop(columns=['ClaimNb', 'Frequency', 'IDpol'])\n",
    "\n",
    "# Keep Exposure separately for Poisson regression (weights)\n",
    "exposure = df1['Exposure']\n",
    "\n",
    "X_train, X_test, y_train, y_test, exp_train, exp_test = train_test_split(\n",
    "    X, y, exposure, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55005741",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "We compare several regression models on the count variable `ClaimNb`:\n",
    "\n",
    "- Linear Regression (baseline, not theoretically suitable but useful as simple reference)\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Linear SVR (maximum margin model)\n",
    "- Poisson Regression (`PoissonRegressor`) with `Exposure` as weights\n",
    "\n",
    "We use **MSE** (Mean Squared Error) for initial comparison, then **Poisson deviance**, more suitable for count data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5119624",
   "metadata": {},
   "source": [
    "### 5.1 Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a693946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear Regression] MSE = 0.057193\n",
      "[Linear Regression] R²  = 0.012396\n"
     ]
    }
   ],
   "source": [
    "lin_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "\n",
    "lin_pipeline.fit(X_train, y_train)\n",
    "y_pred_lin = lin_pipeline.predict(X_test)\n",
    "\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "\n",
    "print(f\"[Linear Regression] MSE = {mse_lin:.6f}\")\n",
    "print(f\"[Linear Regression] R²  = {r2_lin:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc090f4e",
   "metadata": {},
   "source": [
    "### 5.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c5d6565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decision Tree] MSE = 0.057129\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "print(f\"[Decision Tree] MSE = {mse_tree:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2fb64",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78777dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Forest] MSE = 0.056007\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"[Random Forest] MSE = {mse_rf:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e23f0",
   "metadata": {},
   "source": [
    "### 5.4 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d691249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gradient Boosting] MSE = 0.056125\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "print(f\"[Gradient Boosting] MSE = {mse_gb:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c4b38",
   "metadata": {},
   "source": [
    "### 5.5 Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee11eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVR] MSE = 0.060792\n"
     ]
    }
   ],
   "source": [
    "svr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', LinearSVR(random_state=42, dual='auto'))\n",
    "])\n",
    "\n",
    "svr_pipeline.fit(X_train, y_train)\n",
    "y_pred_svr = svr_pipeline.predict(X_test)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "print(f\"[SVR] MSE = {mse_svr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5714d443",
   "metadata": {},
   "source": [
    "### 5.6 Poisson Regression (Poisson GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9b160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Poisson Regression] MSE = 0.057835\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Poisson (remove Exposure from features)\n",
    "X_train_pois = X_train.drop(columns=[\"Exposure\"])\n",
    "X_test_pois = X_test.drop(columns=[\"Exposure\"])\n",
    "\n",
    "pois = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "\n",
    "# Use exposure as weights (approximation of offset)\n",
    "pois.fit(X_train_pois, y_train, sample_weight=exp_train)\n",
    "y_pred_pois = pois.predict(X_test_pois)\n",
    "\n",
    "mse_pois = mean_squared_error(y_test, y_pred_pois)\n",
    "print(f\"[Poisson Regression] MSE = {mse_pois:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5aa75e",
   "metadata": {},
   "source": [
    "## 6. Model Comparison\n",
    "\n",
    "We now compare models using two metrics:\n",
    "\n",
    "- **MSE**: Mean Squared Error (classic, but not ideal for Poisson data)\n",
    "- **Poisson deviance**: Metric suitable for count data (lower = better model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b183150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th></th><th>Model</th><th>MSE</th><th>Poisson Deviance</th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th>2</th><td>Random Forest</td><td>0.056007</td><td>0.296271</td></tr>\n",
       "    <tr><th>3</th><td>Gradient Boosting</td><td>0.056125</td><td>0.298513</td></tr>\n",
       "    <tr><th>1</th><td>Decision Tree</td><td>0.057129</td><td>0.305238</td></tr>\n",
       "    <tr><th>0</th><td>Linear Regression</td><td>0.057193</td><td>0.315877</td></tr>\n",
       "    <tr><th>5</th><td>Poisson Regression</td><td>0.057835</td><td>0.319758</td></tr>\n",
       "    <tr><th>4</th><td>Linear SVR</td><td>0.060792</td><td>2.125633</td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model       MSE  Poisson Deviance\n",
       "2       Random Forest  0.056007          0.296271\n",
       "3   Gradient Boosting  0.056125          0.298513\n",
       "1       Decision Tree  0.057129          0.305238\n",
       "0   Linear Regression  0.057193          0.315877\n",
       "5  Poisson Regression  0.057835          0.319758\n",
       "4          Linear SVR  0.060792          2.125633"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_pred(y_pred):\n",
    "    # Poisson deviance requires strictly positive predictions\n",
    "    return np.maximum(y_pred, 1e-9)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Linear Regression',\n",
    "        'Decision Tree',\n",
    "        'Random Forest',\n",
    "        'Gradient Boosting',\n",
    "        'Linear SVR',\n",
    "        'Poisson Regression'\n",
    "    ],\n",
    "    'MSE': [\n",
    "        mse_lin,\n",
    "        mse_tree,\n",
    "        mse_rf,\n",
    "        mse_gb,\n",
    "        mse_svr,\n",
    "        mse_pois\n",
    "    ],\n",
    "    'Poisson Deviance': [\n",
    "        mean_poisson_deviance(y_test, safe_pred(y_pred_lin)),\n",
    "        mean_poisson_deviance(y_test, safe_pred(y_pred_tree)),\n",
    "        mean_poisson_deviance(y_test, safe_pred(y_pred_rf)),\n",
    "        mean_poisson_deviance(y_test, safe_pred(y_pred_gb)),\n",
    "        mean_poisson_deviance(y_test, safe_pred(y_pred_svr)),\n",
    "        mean_poisson_deviance(y_test, safe_pred(y_pred_pois)),\n",
    "    ]\n",
    "})\n",
    "\n",
    "results.sort_values(by='Poisson Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c04070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th></th><th>Model</th><th>MSE</th><th>Poisson Deviance</th><th>R2</th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th>2</th><td>Random Forest</td><td>0.056007</td><td>0.296271</td><td>0.032902</td></tr>\n",
       "    <tr><th>3</th><td>Gradient Boosting</td><td>0.056125</td><td>0.298513</td><td>0.030842</td></tr>\n",
       "    <tr><th>1</th><td>Decision Tree</td><td>0.057129</td><td>0.305238</td><td>0.013516</td></tr>\n",
       "    <tr><th>0</th><td>Linear Regression</td><td>0.057193</td><td>0.315877</td><td>0.012396</td></tr>\n",
       "    <tr><th>5</th><td>Poisson Regression</td><td>0.057835</td><td>0.319758</td><td>0.001311</td></tr>\n",
       "    <tr><th>4</th><td>Linear SVR</td><td>0.060792</td><td>2.125633</td><td>-0.049741</td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model       MSE  Poisson Deviance        R2\n",
       "2       Random Forest  0.056007          0.296271  0.032902\n",
       "3   Gradient Boosting  0.056125          0.298513  0.030842\n",
       "1       Decision Tree  0.057129          0.305238  0.013516\n",
       "0   Linear Regression  0.057193          0.315877  0.012396\n",
       "5  Poisson Regression  0.057835          0.319758  0.001311\n",
       "4          Linear SVR  0.060792          2.125633 -0.049741"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add R² for complete comparison\n",
    "results['R2'] = [\n",
    "    r2_score(y_test, y_pred_lin),\n",
    "    r2_score(y_test, y_pred_tree),\n",
    "    r2_score(y_test, y_pred_rf),\n",
    "    r2_score(y_test, y_pred_gb),\n",
    "    r2_score(y_test, y_pred_svr),\n",
    "    r2_score(y_test, y_pred_pois)\n",
    "]\n",
    "\n",
    "results.sort_values(by='R2', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d72e67",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- **Random Forest** and **Gradient Boosting** achieve the best performance in terms of both MSE and Poisson deviance\n",
    "- **Poisson Regression**, despite lower MSE than Linear SVR, shows intermediate Poisson deviance — theoretically appropriate for count data but limited by its log-linear structure\n",
    "- **Linear SVR** has very high Poisson deviance (>2), suggesting it predicts negative or near-zero values, which is problematic for count data\n",
    "- **R² is low for all models** (~3% max), which is expected for rare count data where individual predictions are inherently uncertain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2aa68b",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Optimization (Poisson GLM)\n",
    "\n",
    "We use **GridSearchCV** to find the optimal regularization parameter for Poisson regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gridsearch_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for Poisson\n",
    "param_grid_pois = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gridsearch_fit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=PoissonRegressor(max_iter=2000), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]},\n",
       "             scoring='neg_mean_poisson_deviance', verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base Poisson model (GLM log-linear structure)\n",
    "pois_base = PoissonRegressor(\n",
    "    max_iter=2000,\n",
    "    fit_intercept=True\n",
    ")\n",
    "\n",
    "# GridSearchCV:\n",
    "# - tries all hyperparameter combinations in param_grid_pois\n",
    "# - for each combination, performs cross-validation (cv=3)\n",
    "# - evaluates models with neg_mean_poisson_deviance\n",
    "grid_pois = GridSearchCV(\n",
    "    estimator=pois_base,\n",
    "    param_grid=param_grid_pois,\n",
    "    scoring=\"neg_mean_poisson_deviance\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Pass exposure as weights\n",
    "grid_pois.fit(X_train_pois, y_train, sample_weight=exp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9dbe618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha found: 0.0001\n",
      "Best mean deviance (CV): 0.3185226923615155\n"
     ]
    }
   ],
   "source": [
    "print(\"Best alpha found:\", grid_pois.best_params_[\"alpha\"])\n",
    "print(\"Best mean deviance (CV):\", -grid_pois.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7965ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Poisson MSE (test)      : 0.057835\n",
      "Optimized Poisson deviance (test) : 0.319758\n"
     ]
    }
   ],
   "source": [
    "# Best Poisson model found by GridSearchCV\n",
    "pois_best = grid_pois.best_estimator_\n",
    "\n",
    "# Predictions on train and test\n",
    "y_pred_pois_train = pois_best.predict(X_train_pois)\n",
    "y_pred_pois_test = pois_best.predict(X_test_pois)\n",
    "\n",
    "# MSE and Poisson deviance on test\n",
    "mse_pois_test = mean_squared_error(y_test, y_pred_pois_test)\n",
    "dev_pois_test = mean_poisson_deviance(y_test, y_pred_pois_test)\n",
    "\n",
    "print(f\"Optimized Poisson MSE (test)      : {mse_pois_test:.6f}\")\n",
    "print(f\"Optimized Poisson deviance (test) : {dev_pois_test:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d5214",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The Poisson regression optimization via GridSearchCV confirmed that the initial model was already using the optimal hyperparameter (alpha = 1e-4).\n",
    "The performance obtained after optimization (MSE = 0.057835, deviance = 0.319758) is identical to the base Poisson model.\n",
    "This result is consistent with the nature of the Poisson GLM model, which remains limited by its log-linear structure.\n",
    "To achieve significant gains, it would be necessary to introduce non-linear transformations (splines, interactions) or more flexible Poisson models (GAM, XGBoost Poisson)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e576d",
   "metadata": {},
   "source": [
    "## 8. Effect of Resampling on Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79277ceb",
   "metadata": {},
   "source": [
    "### 8.1 Building a Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3410b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean: 0.05329171203299764\n",
      "Resampled mean: 0.1852281654848035\n"
     ]
    }
   ],
   "source": [
    "df_resampled = df1.copy()\n",
    "\n",
    "# Isolate claims (ClaimNb > 0)\n",
    "df_pos = df1[df1[\"ClaimNb\"] > 0]\n",
    "\n",
    "# Duplicate claims 3x\n",
    "df_resampled = pd.concat([\n",
    "    df1,\n",
    "    df_pos,\n",
    "    df_pos,\n",
    "    df_pos\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"Original mean:\", df1[\"ClaimNb\"].mean())\n",
    "print(\"Resampled mean:\", df_resampled[\"ClaimNb\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae0054",
   "metadata": {},
   "source": [
    "### 8.2 Train/Test Split on Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ef9f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = df_resampled.drop(columns=[\"ClaimNb\", \"Frequency\", \"IDpol\"])\n",
    "y_res = df_resampled[\"ClaimNb\"]\n",
    "expo_res = df_resampled[\"Exposure\"]\n",
    "\n",
    "X_train_res, X_test_res, y_train_res, y_test_res, expo_train_res, expo_test_res = train_test_split(\n",
    "    X_res, y_res, expo_res, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab550f1",
   "metadata": {},
   "source": [
    "### 8.3 Poisson Regression on Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2066c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Poisson MSE: 0.17719903583090857\n",
      "Resampled Poisson deviance: 0.6601077743837559\n"
     ]
    }
   ],
   "source": [
    "# Prepare X for Poisson: remove Exposure\n",
    "X_train_pois_res = X_train_res.drop(columns=[\"Exposure\"])\n",
    "X_test_pois_res = X_test_res.drop(columns=[\"Exposure\"])\n",
    "\n",
    "# Fit\n",
    "pois_res = PoissonRegressor(alpha=1e-4, max_iter=1000)\n",
    "pois_res.fit(X_train_pois_res, y_train_res, sample_weight=expo_train_res)\n",
    "\n",
    "# Predict\n",
    "y_pred_pois_res = pois_res.predict(X_test_pois_res)\n",
    "\n",
    "# Safe predictions for deviance\n",
    "y_pred_safe_res = np.maximum(y_pred_pois_res, 1e-9)\n",
    "\n",
    "print(\"Resampled Poisson MSE:\", mean_squared_error(y_test_res, y_pred_pois_res))\n",
    "print(\"Resampled Poisson deviance:\", mean_poisson_deviance(y_test_res, y_pred_safe_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "| Model | MSE | Poisson Deviance | R² |\n",
    "|-------|-----|------------------|----|\n",
    "| **Random Forest** | 0.056007 | 0.296271 | 0.0329 |\n",
    "| **Gradient Boosting** | 0.056125 | 0.298513 | 0.0308 |\n",
    "| Decision Tree | 0.057129 | 0.305238 | 0.0135 |\n",
    "| Linear Regression | 0.057193 | 0.315877 | 0.0124 |\n",
    "| Poisson Regression | 0.057835 | 0.319758 | 0.0013 |\n",
    "| Linear SVR | 0.060792 | 2.125633 | -0.0497 |\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **For Predictive Accuracy**: Use **Random Forest** or **Gradient Boosting** — they achieve the best MSE and Poisson deviance\n",
    "\n",
    "2. **For Regulatory Compliance**: Use **Poisson GLM** — it offers interpretable coefficients required by insurance regulators\n",
    "\n",
    "3. **For Production**: Consider **XGBoost with Poisson objective** — combines ensemble performance with proper count data handling\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "- Implement GAM (Generalized Additive Models) for non-linear effects with interpretability\n",
    "- Try Zero-Inflated Poisson for excess zeros\n",
    "- Add feature interactions (Age × Vehicle type)\n",
    "- Use SHAP values for model explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
